{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define 4 PSO(Particle Swarm Optimization) algorithms to adjust the parameter\n",
    "\n",
    "1. RF_PSO (Random Forest)，ADA_PSO (Adaboost)，GBDT_PSO output: the sequence of predicted returns of stocks in each time cross-section\n",
    "2. Rolling training --> sec is the ranking of stock returns\n",
    "\n",
    "Delete features that are missing more than 5% at each time cross-section, and then delete samples with missing values\n",
    "\n",
    "The importance of 209 candidate factors is obtained by Decision Tree and selected according to the importance.\n",
    "\n",
    "1. The number of features in different time cross-sections is different. To prevent over-fitting, when building a predictive model with three models for each time cross-section, a maximum of 10 features can be used.\n",
    "2. Feature selection and modeling of three prediction models are done on 121 time cross-sections.\n",
    "3. Add up the feature importance of the selected feature of each time cross-section: \"特征重要度汇总.xls\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tree_PSO\n",
    "    用于特征筛选时，调参决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------PSO参数设置---------------------------------\n",
    "class tree_PSO():\n",
    "    def __init__(self, pN, dim, max_iter, train_x, train_y):\n",
    "        self.w = 0.8    #设置较大的W和较小的C避免负参数\n",
    "        self.c1 = 2\n",
    "        self.c2 = 2\n",
    "        self.r1 = 0.6\n",
    "        self.r2 = 0.3\n",
    "        self.pN = pN  # 粒子数量\n",
    "        self.dim = dim  # 搜索维度\n",
    "        self.max_iter = max_iter  # 迭代次数\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.X = np.zeros((self.pN, self.dim))  # 所有粒子的位置和速度\n",
    "        self.V = np.zeros((self.pN, self.dim))\n",
    "        self.pbest = np.zeros((self.pN, self.dim))  # 个体经历的最佳位置和全局最佳位置\n",
    "        self.gbest = np.zeros((1, self.dim))\n",
    "        self.p_fit = np.zeros(self.pN)  # 每个个体的历史最佳适应值\n",
    "        self.fit = 0.6# 全局最佳适应值\n",
    "\n",
    "# ---------------------目标函数Sphere函数-----------------------------\n",
    "    def function(self, X, train_x, train_y):\n",
    "        # 适应度函数为model的CV3平均值\n",
    "        Model = tree.DecisionTreeRegressor(\n",
    "                                        criterion='mse',\n",
    "                                        splitter='best',\n",
    "                                        max_depth=X[0],\n",
    "                                        min_samples_split=X[1],\n",
    "                                        min_samples_leaf=X[2],\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        max_features=None,\n",
    "                                        random_state=None,\n",
    "                                        max_leaf_nodes=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        ccp_alpha=0.0,\n",
    "                                    )\n",
    "        \n",
    "        cv_scores = model_selection.cross_validate(Model,\n",
    "                                                   x,\n",
    "                                                   y,\n",
    "                                                   groups=None,\n",
    "                                                   scoring=\"r2\",  #适应度函数\n",
    "                                                   cv=3,\n",
    "                                                   verbose=0,\n",
    "                                                   fit_params=None,\n",
    "                                                   pre_dispatch='2*n_jobs',\n",
    "                                                   return_train_score=False,\n",
    "                                                   return_estimator=False,\n",
    "                                                   )\n",
    "                                                       \n",
    "        return cv_scores[\"test_score\"].mean()  #3个交叉验证的均值\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # ---------------------初始化种群----------------------------------\n",
    "    def init_Population(self):\n",
    "        for i in range(self.pN):\n",
    "            \n",
    "            self.X[i][0] = random.randint(2,12)  \n",
    "            self.V[i][0] = random.randint(1,3)  \n",
    "            \n",
    "            self.X[i][1] = random.randint(10,50)\n",
    "            self.V[i][1] = random.randint(1,5)\n",
    "            \n",
    "            self.X[i][2] = random.randint(5,30)\n",
    "            self.V[i][2] = random.randint(1,3)\n",
    "            \n",
    "            self.pbest[i] = self.X[i]\n",
    "            tmp = self.function(self.X[i],self.train_x,self.train_y)\n",
    "            self.p_fit[i] = tmp\n",
    "            if tmp > self.fit:\n",
    "                self.fit = tmp\n",
    "                self.gbest = self.X[i]\n",
    "\n",
    "                # ----------------------更新粒子位置----------------------------------\n",
    "\n",
    "    def iterator(self):\n",
    "        fitness = []\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.pN):  # 更新gbest\\pbest\n",
    "                temp = self.function(self.X[i],self.train_x,self.train_y)\n",
    "                if temp > self.p_fit[i]:  # 更新个体最优\n",
    "                    self.p_fit[i] = temp\n",
    "                    self.pbest[i] = self.X[i]\n",
    "                    if self.p_fit[i] > self.fit:  # 更新全局最优\n",
    "                        self.gbest = self.X[i]\n",
    "                        self.fit = self.p_fit[i]\n",
    "            for i in range(self.pN):\n",
    "                self.V[i] = self.w * self.V[i] + self.c1 * self.r1 * (self.pbest[i] - self.X[i]) + \\\n",
    "                            self.c2 * self.r2 * (self.gbest - self.X[i])\n",
    "                self.X[i] = self.X[i] + self.V[i]\n",
    "                \n",
    "                #约束参数数据类型\n",
    "                self.X[i][0] = int(self.X[i][0])\n",
    "                self.X[i][1] = int(self.X[i][1])\n",
    "                self.X[i][2] = int(self.X[i][2])\n",
    "                \n",
    "                #约束参数最小值\n",
    "                if self.X[i][0] < 2:\n",
    "                    self.X[i][0] = 2\n",
    "                if self.X[i][1] < 2:\n",
    "                    self.X[i][1] = 1\n",
    "                if self.X[i][2] < 1:\n",
    "                    self.X[i][2] = 1\n",
    "                \n",
    "            fitness.append(self.fit)\n",
    "            #print(self.X[0], end=\" \")\n",
    "            #print(self.fit)  # 输出最优值\n",
    "        return fitness,self.X[0]\n",
    "\n",
    "\n",
    "def factor_select(x,y):\n",
    "\n",
    "\n",
    "    my_pso = tree_PSO(pN=20, dim=3, max_iter=10, train_x=x,train_y=y)\n",
    "    my_pso.init_Population()\n",
    "    fitness,params = my_pso.iterator()\n",
    "\n",
    "    Model = tree.DecisionTreeRegressor(\n",
    "                        criterion='mse',\n",
    "                        splitter='best',\n",
    "                        max_depth=int(params[0]),\n",
    "                        min_samples_split=int(params[1]),\n",
    "                        min_samples_leaf=int(params[2]),\n",
    "                        min_weight_fraction_leaf=0.0,\n",
    "                        max_features=None,\n",
    "                        random_state=None,\n",
    "                        max_leaf_nodes=None,\n",
    "                        min_impurity_decrease=0.0,\n",
    "                        min_impurity_split=None,\n",
    "                        ccp_alpha=0.0,\n",
    "                    )\n",
    "    Model.fit(x,y)\n",
    "\n",
    "    fdf = pd.DataFrame()\n",
    "    fdf['feature'] = xdf.columns\n",
    "    fdf['importances'] = Model.feature_importances_\n",
    "    fdf = fdf.query('importances>0')\n",
    "    fdf = fdf.sort_values(by='importances',ascending=False)\n",
    "    fdf.index = range(len(fdf))\n",
    "    fdf = fdf[:10]\n",
    "    factor = list(fdf['feature'])\n",
    "    return fdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF_PSO\n",
    "    随机森林调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------PSO参数设置---------------------------------\n",
    "class RF_PSO():\n",
    "    def __init__(self, pN, dim, max_iter, train_x, train_y):\n",
    "        self.w = 0.8    #设置较大的W和较小的C避免负参数\n",
    "        self.c1 = 2\n",
    "        self.c2 = 2\n",
    "        self.r1 = 0.6\n",
    "        self.r2 = 0.3\n",
    "        self.pN = pN  # 粒子数量\n",
    "        self.dim = dim  # 搜索维度\n",
    "        self.max_iter = max_iter  # 迭代次数\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.X = np.zeros((self.pN, self.dim))  # 所有粒子的位置和速度\n",
    "        self.V = np.zeros((self.pN, self.dim))\n",
    "        self.pbest = np.zeros((self.pN, self.dim))  # 个体经历的最佳位置和全局最佳位置\n",
    "        self.gbest = np.zeros((1, self.dim))\n",
    "        self.p_fit = np.zeros(self.pN)  # 每个个体的历史最佳适应值\n",
    "        self.fit = 0.6# 全局最佳适应值\n",
    "\n",
    "    # ---------------------目标函数Sphere函数-----------------------------\n",
    "    def function(self, X, train_x, train_y):\n",
    "        # 适应度函数为model的CV3平均值\n",
    "        Model = ensemble.RandomForestRegressor(\n",
    "                                    n_estimators=X[0],\n",
    "                                    criterion='mse',\n",
    "                                    max_depth=X[1],\n",
    "                                    min_samples_split=X[2],\n",
    "                                    min_samples_leaf=X[3],\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    max_features='auto',\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_impurity_split=None,\n",
    "                                    bootstrap=True,\n",
    "                                    oob_score=False,\n",
    "                                    n_jobs=None,\n",
    "                                    random_state=None,\n",
    "                                    verbose=0,\n",
    "                                    warm_start=False,\n",
    "                                    ccp_alpha=0.0,\n",
    "                                    max_samples=None,\n",
    "                                )\n",
    "        cv_scores = model_selection.cross_validate(Model,\n",
    "                                                   x,\n",
    "                                                   y,\n",
    "                                                   groups=None,\n",
    "                                                   scoring=\"r2\",  #适应度函数\n",
    "                                                   cv=3,\n",
    "                                                   verbose=0,\n",
    "                                                   fit_params=None,\n",
    "                                                   pre_dispatch='2*n_jobs',\n",
    "                                                   return_train_score=False,\n",
    "                                                   return_estimator=False,\n",
    "                                                   )\n",
    "                                                       \n",
    "        return cv_scores[\"test_score\"].mean()  #5个交叉验证的均值\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # ---------------------初始化种群----------------------------------\n",
    "    def init_Population(self):\n",
    "        for i in range(self.pN):\n",
    "            \n",
    "            self.X[i][0] = random.randint(50,150)  \n",
    "            self.V[i][0] = random.randint(10,20)  \n",
    "            \n",
    "            self.X[i][1] = random.randint(1,10)\n",
    "            self.V[i][1] = random.randint(1,3)\n",
    "            \n",
    "            self.X[i][2] = random.randint(5,50)\n",
    "            self.V[i][2] = random.randint(1,5)\n",
    "            \n",
    "            self.X[i][3] = random.randint(5,50)\n",
    "            self.V[i][3] = random.randint(1,5)\n",
    "            \n",
    "            self.pbest[i] = self.X[i]\n",
    "            tmp = self.function(self.X[i],self.train_x,self.train_y)\n",
    "            self.p_fit[i] = tmp\n",
    "            if tmp > self.fit:\n",
    "                self.fit = tmp\n",
    "                self.gbest = self.X[i]\n",
    "\n",
    "                # ----------------------更新粒子位置----------------------------------\n",
    "\n",
    "    def iterator(self):\n",
    "        fitness = []\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.pN):  # 更新gbest\\pbest\n",
    "                temp = self.function(self.X[i],self.train_x,self.train_y)\n",
    "                if temp > self.p_fit[i]:  # 更新个体最优\n",
    "                    self.p_fit[i] = temp\n",
    "                    self.pbest[i] = self.X[i]\n",
    "                    if self.p_fit[i] > self.fit:  # 更新全局最优\n",
    "                        self.gbest = self.X[i]\n",
    "                        self.fit = self.p_fit[i]\n",
    "            for i in range(self.pN):\n",
    "                self.V[i] = self.w * self.V[i] + self.c1 * self.r1 * (self.pbest[i] - self.X[i]) + \\\n",
    "                            self.c2 * self.r2 * (self.gbest - self.X[i])\n",
    "                self.X[i] = self.X[i] + self.V[i]\n",
    "                \n",
    "                #约束参数数据类型\n",
    "                self.X[i][0] = int(self.X[i][0])\n",
    "                self.X[i][1] = int(self.X[i][1])\n",
    "                self.X[i][2] = int(self.X[i][2])\n",
    "                self.X[i][3] = int(self.X[i][3])\n",
    "                \n",
    "                #约束参数最小值\n",
    "                if self.X[i][0] < 50:\n",
    "                    self.X[i][0] = 50\n",
    "                if self.X[i][1] < 1:\n",
    "                    self.X[i][1] = 1\n",
    "                if self.X[i][2] < 2:\n",
    "                    self.X[i][2] = 2\n",
    "                if self.X[i][3] < 1:\n",
    "                    self.X[i][3] = 1\n",
    "                \n",
    "            fitness.append(self.fit)\n",
    "            #print(self.X[0], end=\" \")\n",
    "            #print(self.fit)  # 输出最优值\n",
    "        return fitness,self.X[0]\n",
    "    \n",
    "\n",
    "def RF_fun(x,y,predict):\n",
    "    my_pso = RF_PSO(pN=20, dim=4, max_iter=10, train_x=x,train_y=y)\n",
    "    my_pso.init_Population()\n",
    "    fitness,params = my_pso.iterator()\n",
    "\n",
    "    Model = ensemble.RandomForestRegressor(\n",
    "                    n_estimators=int(params[0]),\n",
    "                    criterion='mse',\n",
    "                    max_depth=int(params[1]),\n",
    "                    min_samples_split=int(params[2]),\n",
    "                    min_samples_leaf=int(params[3]),\n",
    "                    min_weight_fraction_leaf=0.0,\n",
    "                    max_features='auto',\n",
    "                    max_leaf_nodes=None,\n",
    "                    min_impurity_decrease=0.0,\n",
    "                    min_impurity_split=None,\n",
    "                    bootstrap=True,\n",
    "                    oob_score=False,\n",
    "                    n_jobs=None,\n",
    "                    random_state=None,\n",
    "                    verbose=0,\n",
    "                    warm_start=False,\n",
    "                    ccp_alpha=0.0,\n",
    "                    max_samples=None,\n",
    "                )\n",
    "    Model.fit(x,y)\n",
    "\n",
    "    predict_return = Model.predict(predict.values)\n",
    "    return predict_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA_PSO\n",
    "    用于Adaboost调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------PSO参数设置---------------------------------\n",
    "class ADA_PSO():\n",
    "    def __init__(self, pN, dim, max_iter, train_x, train_y):\n",
    "        self.w = 0.8    #设置较大的W和较小的C避免负参数\n",
    "        self.c1 = 2\n",
    "        self.c2 = 2\n",
    "        self.r1 = 0.6\n",
    "        self.r2 = 0.3\n",
    "        self.pN = pN  # 粒子数量\n",
    "        self.dim = dim  # 搜索维度\n",
    "        self.max_iter = max_iter  # 迭代次数\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.X = np.zeros((self.pN, self.dim))  # 所有粒子的位置和速度\n",
    "        self.V = np.zeros((self.pN, self.dim))\n",
    "        self.pbest = np.zeros((self.pN, self.dim))  # 个体经历的最佳位置和全局最佳位置\n",
    "        self.gbest = np.zeros((1, self.dim))\n",
    "        self.p_fit = np.zeros(self.pN)  # 每个个体的历史最佳适应值\n",
    "        self.fit = 0.6# 全局最佳适应值\n",
    "\n",
    "    # ---------------------目标函数Sphere函数-----------------------------\n",
    "    def function(self, X, train_x, train_y):\n",
    "        # 适应度函数为model的CV3平均值\n",
    "        Model = ensemble.AdaBoostRegressor(\n",
    "                            base_estimator=None,\n",
    "                            n_estimators=X[0],\n",
    "                            learning_rate=X[1],\n",
    "                            loss='linear',\n",
    "                            random_state=None,\n",
    "                        )\n",
    "        cv_scores = model_selection.cross_validate(Model,\n",
    "                                                   x,\n",
    "                                                   y,\n",
    "                                                   groups=None,\n",
    "                                                   scoring=\"r2\",  #适应度函数\n",
    "                                                   cv=3,\n",
    "                                                   verbose=0,\n",
    "                                                   fit_params=None,\n",
    "                                                   pre_dispatch='2*n_jobs',\n",
    "                                                   return_train_score=False,\n",
    "                                                   return_estimator=False,\n",
    "                                                   )\n",
    "                                                       \n",
    "        return cv_scores[\"test_score\"].mean()  #5个交叉验证的均值\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # ---------------------初始化种群----------------------------------\n",
    "    def init_Population(self):\n",
    "        for i in range(self.pN):\n",
    "            \n",
    "            self.X[i][0] = random.randint(50,150)  \n",
    "            self.V[i][0] = random.randint(10,20)  \n",
    "            \n",
    "            self.X[i][1] = random.uniform(0.1,1.2)\n",
    "            self.V[i][1] = random.uniform(0.1,0.5)\n",
    "            \n",
    "            self.pbest[i] = self.X[i]\n",
    "            tmp = self.function(self.X[i],self.train_x,self.train_y)\n",
    "            self.p_fit[i] = tmp\n",
    "            if tmp > self.fit:\n",
    "                self.fit = tmp\n",
    "                self.gbest = self.X[i]\n",
    "\n",
    "                # ----------------------更新粒子位置----------------------------------\n",
    "\n",
    "    def iterator(self):\n",
    "        fitness = []\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.pN):  # 更新gbest\\pbest\n",
    "                temp = self.function(self.X[i],self.train_x,self.train_y)\n",
    "                if temp > self.p_fit[i]:  # 更新个体最优\n",
    "                    self.p_fit[i] = temp\n",
    "                    self.pbest[i] = self.X[i]\n",
    "                    if self.p_fit[i] > self.fit:  # 更新全局最优\n",
    "                        self.gbest = self.X[i]\n",
    "                        self.fit = self.p_fit[i]\n",
    "            for i in range(self.pN):\n",
    "                self.V[i] = self.w * self.V[i] + self.c1 * self.r1 * (self.pbest[i] - self.X[i]) + \\\n",
    "                            self.c2 * self.r2 * (self.gbest - self.X[i])\n",
    "                self.X[i] = self.X[i] + self.V[i]\n",
    "                \n",
    "                #约束参数数据类型\n",
    "                self.X[i][0] = int(self.X[i][0])\n",
    "                \n",
    "                #约束参数最小值\n",
    "                if self.X[i][0] < 50:\n",
    "                    self.X[i][0] = 50\n",
    "                if self.X[i][1] < 0:\n",
    "                    self.X[i][1] = 0.1\n",
    "                \n",
    "            fitness.append(self.fit)\n",
    "            #print(self.X[0], end=\" \")\n",
    "            #print(self.fit)  # 输出最优值\n",
    "        return fitness,self.X[0]\n",
    "    \n",
    "\n",
    "def ADA_fun(x,y,predict):\n",
    "    my_pso = ADA_PSO(pN=20, dim=2, max_iter=10, train_x=x,train_y=y)\n",
    "    my_pso.init_Population()\n",
    "    fitness,params = my_pso.iterator()\n",
    "\n",
    "    Model = ensemble.AdaBoostRegressor(\n",
    "                            base_estimator=None,\n",
    "                            n_estimators=int(params[0]),\n",
    "                            learning_rate=params[1],\n",
    "                            loss='linear',\n",
    "                            random_state=None,\n",
    "                        )\n",
    "    Model.fit(x,y)\n",
    "\n",
    "    predict_return = Model.predict(predict.values)\n",
    "    return predict_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT_PSO\n",
    "    用于GBDT调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------PSO参数设置---------------------------------\n",
    "class GBDT_PSO():\n",
    "    def __init__(self, pN, dim, max_iter, train_x, train_y):\n",
    "        self.w = 0.8    #设置较大的W和较小的C避免负参数\n",
    "        self.c1 = 2\n",
    "        self.c2 = 2\n",
    "        self.r1 = 0.6\n",
    "        self.r2 = 0.3\n",
    "        self.pN = pN  # 粒子数量\n",
    "        self.dim = dim  # 搜索维度\n",
    "        self.max_iter = max_iter  # 迭代次数\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.X = np.zeros((self.pN, self.dim))  # 所有粒子的位置和速度\n",
    "        self.V = np.zeros((self.pN, self.dim))\n",
    "        self.pbest = np.zeros((self.pN, self.dim))  # 个体经历的最佳位置和全局最佳位置\n",
    "        self.gbest = np.zeros((1, self.dim))\n",
    "        self.p_fit = np.zeros(self.pN)  # 每个个体的历史最佳适应值\n",
    "        self.fit = 0.6# 全局最佳适应值\n",
    "\n",
    "    # ---------------------目标函数Sphere函数-----------------------------\n",
    "    def function(self, X, train_x, train_y):\n",
    "        # 适应度函数为model的CV3平均值\n",
    "        Model = ensemble.GradientBoostingRegressor(\n",
    "                                            loss='ls',\n",
    "                                            learning_rate=X[0],\n",
    "                                            n_estimators=100,\n",
    "                                            subsample=1.0,\n",
    "                                            criterion='friedman_mse',\n",
    "                                            min_samples_split=X[1],\n",
    "                                            min_samples_leaf=X[2],\n",
    "                                            min_weight_fraction_leaf=0.0,\n",
    "                                            max_depth=X[3],\n",
    "                                            min_impurity_decrease=0.0,\n",
    "                                            min_impurity_split=None,\n",
    "                                            init=None,\n",
    "                                            random_state=None,\n",
    "                                            max_features=None,\n",
    "                                            alpha=0.9,\n",
    "                                            verbose=0,\n",
    "                                            max_leaf_nodes=None,\n",
    "                                            warm_start=False,\n",
    "                                            validation_fraction=0.1,\n",
    "                                            n_iter_no_change=None,\n",
    "                                            tol=0.0001,\n",
    "                                            ccp_alpha=0.0,\n",
    "                                        )\n",
    "        cv_scores = model_selection.cross_validate(Model,\n",
    "                                                   x,\n",
    "                                                   y,\n",
    "                                                   groups=None,\n",
    "                                                   scoring=\"r2\",  #适应度函数\n",
    "                                                   cv=3,\n",
    "                                                   verbose=0,\n",
    "                                                   fit_params=None,\n",
    "                                                   pre_dispatch='2*n_jobs',\n",
    "                                                   return_train_score=False,\n",
    "                                                   return_estimator=False,\n",
    "                                                   )\n",
    "                                                       \n",
    "        return cv_scores[\"test_score\"].mean()  #5个交叉验证的均值\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # ---------------------初始化种群----------------------------------\n",
    "    def init_Population(self):\n",
    "        for i in range(self.pN):\n",
    "            \n",
    "            self.X[i][0] = random.uniform(0.1,1.2)  \n",
    "            self.V[i][0] = random.uniform(0.1,0.5)\n",
    "            \n",
    "            self.X[i][1] = random.randint(5,50)\n",
    "            self.V[i][1] = random.randint(1,5)\n",
    "            \n",
    "            self.X[i][2] = random.randint(5,50)\n",
    "            self.V[i][2] = random.randint(1,5)\n",
    "            \n",
    "            self.X[i][3] = random.randint(1,10)\n",
    "            self.V[i][3] = random.randint(1,3)\n",
    "            \n",
    "            self.pbest[i] = self.X[i]\n",
    "            tmp = self.function(self.X[i],self.train_x,self.train_y)\n",
    "            self.p_fit[i] = tmp\n",
    "            if tmp > self.fit:\n",
    "                self.fit = tmp\n",
    "                self.gbest = self.X[i]\n",
    "\n",
    "                # ----------------------更新粒子位置----------------------------------\n",
    "\n",
    "    def iterator(self):\n",
    "        fitness = []\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.pN):  # 更新gbest\\pbest\n",
    "                temp = self.function(self.X[i],self.train_x,self.train_y)\n",
    "                if temp > self.p_fit[i]:  # 更新个体最优\n",
    "                    self.p_fit[i] = temp\n",
    "                    self.pbest[i] = self.X[i]\n",
    "                    if self.p_fit[i] > self.fit:  # 更新全局最优\n",
    "                        self.gbest = self.X[i]\n",
    "                        self.fit = self.p_fit[i]\n",
    "            for i in range(self.pN):\n",
    "                self.V[i] = self.w * self.V[i] + self.c1 * self.r1 * (self.pbest[i] - self.X[i]) + \\\n",
    "                            self.c2 * self.r2 * (self.gbest - self.X[i])\n",
    "                self.X[i] = self.X[i] + self.V[i]\n",
    "                \n",
    "                #约束参数数据类型\n",
    "                \n",
    "                self.X[i][1] = int(self.X[i][1])\n",
    "                self.X[i][2] = int(self.X[i][2])\n",
    "                self.X[i][3] = int(self.X[i][3])\n",
    "                \n",
    "                #约束参数最小值\n",
    "                if self.X[i][0] < 0:\n",
    "                    self.X[i][0] = 0.1\n",
    "                if self.X[i][1] < 2:\n",
    "                    self.X[i][1] = 2\n",
    "                if self.X[i][2] < 2:\n",
    "                    self.X[i][2] = 2\n",
    "                if self.X[i][3] < 1:\n",
    "                    self.X[i][3] = 1\n",
    "                \n",
    "            fitness.append(self.fit)\n",
    "            #print(self.X[0], end=\" \")\n",
    "            #print(self.fit)  # 输出最优值\n",
    "        return fitness,self.X[0]\n",
    "    \n",
    "\n",
    "def GBDT_fun(x,y,predict):\n",
    "    my_pso = GBDT_PSO(pN=20, dim=4, max_iter=10, train_x=x,train_y=y)\n",
    "    my_pso.init_Population()\n",
    "    fitness,params = my_pso.iterator()\n",
    "\n",
    "    Model = ensemble.GradientBoostingRegressor(\n",
    "                                loss='ls',\n",
    "                                learning_rate=params[0],\n",
    "                                n_estimators=100,\n",
    "                                subsample=1.0,\n",
    "                                criterion='friedman_mse',\n",
    "                                min_samples_split=int(params[1]),\n",
    "                                min_samples_leaf=int(params[2]),\n",
    "                                min_weight_fraction_leaf=0.0,\n",
    "                                max_depth=int(params[3]),\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None,\n",
    "                                init=None,\n",
    "                                random_state=None,\n",
    "                                max_features=None,\n",
    "                                alpha=0.9,\n",
    "                                verbose=0,\n",
    "                                max_leaf_nodes=None,\n",
    "                                warm_start=False,\n",
    "                                validation_fraction=0.1,\n",
    "                                n_iter_no_change=None,\n",
    "                                tol=0.0001,\n",
    "                                ccp_alpha=0.0,\n",
    "                            )\n",
    "    Model.fit(x,y)\n",
    "\n",
    "    predict_return = Model.predict(predict.values)\n",
    "    return predict_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/cr/Downloads/undergraduate time/大四上/FIN 4998/paper/code/机器学习/'\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "from sklearn import preprocessing,tree,ensemble,model_selection,metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdic = pickle.load(open(file+'trade_dic','rb'))\n",
    "df = pickle.load(open(file+'ml_data','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>398240.0</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>1.565157e-01</td>\n",
       "      <td>-8.635171e-01</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069347</td>\n",
       "      <td>6.399758e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peTTM</th>\n",
       "      <td>402643.0</td>\n",
       "      <td>96.135719</td>\n",
       "      <td>1.249271e+04</td>\n",
       "      <td>-7.694016e+05</td>\n",
       "      <td>16.921905</td>\n",
       "      <td>34.652096</td>\n",
       "      <td>66.792843</td>\n",
       "      <td>2.801318e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pbMRQ</th>\n",
       "      <td>402638.0</td>\n",
       "      <td>5.967251</td>\n",
       "      <td>3.108408e+02</td>\n",
       "      <td>-1.021808e+05</td>\n",
       "      <td>1.885265</td>\n",
       "      <td>3.013166</td>\n",
       "      <td>5.038959</td>\n",
       "      <td>2.178802e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcfNcfTTM</th>\n",
       "      <td>402604.0</td>\n",
       "      <td>-452.140136</td>\n",
       "      <td>1.470764e+05</td>\n",
       "      <td>-3.065053e+07</td>\n",
       "      <td>-37.580041</td>\n",
       "      <td>6.663400</td>\n",
       "      <td>45.683559</td>\n",
       "      <td>3.492290e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psTTM</th>\n",
       "      <td>401967.0</td>\n",
       "      <td>15.317529</td>\n",
       "      <td>7.623575e+02</td>\n",
       "      <td>-2.797948e+04</td>\n",
       "      <td>1.609981</td>\n",
       "      <td>3.360850</td>\n",
       "      <td>7.022415</td>\n",
       "      <td>1.371679e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_op_qoq_TTM</th>\n",
       "      <td>191209.0</td>\n",
       "      <td>106.380815</td>\n",
       "      <td>6.750882e+03</td>\n",
       "      <td>-4.045831e+05</td>\n",
       "      <td>0.755875</td>\n",
       "      <td>22.414275</td>\n",
       "      <td>86.403900</td>\n",
       "      <td>4.190297e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_profit_yoy_TTM</th>\n",
       "      <td>181698.0</td>\n",
       "      <td>-13045.824431</td>\n",
       "      <td>1.594203e+06</td>\n",
       "      <td>-1.961631e+08</td>\n",
       "      <td>-26.501675</td>\n",
       "      <td>16.126725</td>\n",
       "      <td>71.120087</td>\n",
       "      <td>3.645647e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_profit_qoq_TTM</th>\n",
       "      <td>191244.0</td>\n",
       "      <td>193.095371</td>\n",
       "      <td>1.364364e+04</td>\n",
       "      <td>-6.849547e+05</td>\n",
       "      <td>2.226937</td>\n",
       "      <td>23.479350</td>\n",
       "      <td>87.733812</td>\n",
       "      <td>1.129425e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_netprofit_yoy_TTM</th>\n",
       "      <td>181704.0</td>\n",
       "      <td>33.109702</td>\n",
       "      <td>5.348248e+03</td>\n",
       "      <td>-2.571226e+05</td>\n",
       "      <td>-26.350563</td>\n",
       "      <td>16.247050</td>\n",
       "      <td>70.956625</td>\n",
       "      <td>3.597948e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_netprofit_qoq_TTM</th>\n",
       "      <td>191264.0</td>\n",
       "      <td>215.249252</td>\n",
       "      <td>1.158096e+04</td>\n",
       "      <td>-2.244657e+05</td>\n",
       "      <td>2.351275</td>\n",
       "      <td>23.404375</td>\n",
       "      <td>88.382575</td>\n",
       "      <td>1.129425e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count          mean           std           min  \\\n",
       "return               398240.0      0.011365  1.565157e-01 -8.635171e-01   \n",
       "peTTM                402643.0     96.135719  1.249271e+04 -7.694016e+05   \n",
       "pbMRQ                402638.0      5.967251  3.108408e+02 -1.021808e+05   \n",
       "pcfNcfTTM            402604.0   -452.140136  1.470764e+05 -3.065053e+07   \n",
       "psTTM                401967.0     15.317529  7.623575e+02 -2.797948e+04   \n",
       "...                       ...           ...           ...           ...   \n",
       "q_op_qoq_TTM         191209.0    106.380815  6.750882e+03 -4.045831e+05   \n",
       "q_profit_yoy_TTM     181698.0 -13045.824431  1.594203e+06 -1.961631e+08   \n",
       "q_profit_qoq_TTM     191244.0    193.095371  1.364364e+04 -6.849547e+05   \n",
       "q_netprofit_yoy_TTM  181704.0     33.109702  5.348248e+03 -2.571226e+05   \n",
       "q_netprofit_qoq_TTM  191264.0    215.249252  1.158096e+04 -2.244657e+05   \n",
       "\n",
       "                           25%        50%        75%           max  \n",
       "return               -0.067831   0.000000   0.069347  6.399758e+00  \n",
       "peTTM                16.921905  34.652096  66.792843  2.801318e+06  \n",
       "pbMRQ                 1.885265   3.013166   5.038959  2.178802e+04  \n",
       "pcfNcfTTM           -37.580041   6.663400  45.683559  3.492290e+07  \n",
       "psTTM                 1.609981   3.360850   7.022415  1.371679e+05  \n",
       "...                        ...        ...        ...           ...  \n",
       "q_op_qoq_TTM          0.755875  22.414275  86.403900  4.190297e+05  \n",
       "q_profit_yoy_TTM    -26.501675  16.126725  71.120087  3.645647e+05  \n",
       "q_profit_qoq_TTM      2.226937  23.479350  87.733812  1.129425e+06  \n",
       "q_netprofit_yoy_TTM -26.350563  16.247050  70.956625  3.597948e+05  \n",
       "q_netprofit_qoq_TTM   2.351275  23.404375  88.382575  1.129425e+06  \n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据的汇总统计描述\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 按时间截面标准化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "daterange = [x[1] for x in df.index.tolist()]\n",
    "daterange = list(set(daterange))\n",
    "daterange.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:24<00:00,  5.36it/s]\n"
     ]
    }
   ],
   "source": [
    "sdf = pd.DataFrame()\n",
    "for d in tqdm(daterange):\n",
    "    temp = df.loc[(slice(None),d),:]\n",
    "    temp.iloc[:,1:] = preprocessing.StandardScaler().fit_transform(temp.iloc[:,1:].values)\n",
    "    \n",
    "    sdf = pd.concat([sdf,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1539"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [46:37<00:00, 23.12s/it]\n"
     ]
    }
   ],
   "source": [
    "fdf_dic = {}\n",
    "sec_dic = {}\n",
    "for day in tqdm(daterange[12:]):\n",
    "    \n",
    "    i = daterange.index(day)\n",
    "    traindate = daterange[i-12:i]\n",
    "    temp = sdf.loc[(slice(None),traindate),:]\n",
    "\n",
    "    temp = temp.dropna(subset=['return'],axis=0)\n",
    "\n",
    "    drop_ = pd.DataFrame(temp.describe().T['count'] / len(temp) < 0.95)   #删除缺失大于5%的\n",
    "    temp = temp.drop(labels=list(drop_.query('count==True').index),axis=1)    \n",
    "    temp = temp.dropna(how='any',axis=0) #删除缺失样本\n",
    "\n",
    "    y = temp['return'].values.reshape(-1,1)\n",
    "    xdf = temp.drop(labels=['return'],axis=1)\n",
    "    x = xdf.values\n",
    "\n",
    "    fdf = factor_select(x,y)\n",
    "\n",
    "\n",
    "    pdf = sdf.loc[(slice(None),day),list(fdf['feature'])] #取排名前10的特征\n",
    "    drop_ = pd.DataFrame(pdf.describe().T['count'] / len(pdf) < 0.2)    #删除缺失过多的特征\n",
    "    pdf = pdf.drop(labels=list(drop_.query('count==True').index),axis=1)\n",
    "    pdf = pdf.dropna(how='any',axis=0)  #删除缺失数据\n",
    "    \n",
    "    xdf = xdf[list(pdf.columns)]  #\n",
    "    x = xdf.values\n",
    "\n",
    "    rf_predict = RF_fun(x,y,pdf)\n",
    "    ada_predict = ADA_fun(x,y,pdf)\n",
    "    gbdt_predict = GBDT_fun(x,y,pdf)\n",
    "\n",
    "    pdf['RF'],pdf['ADA'],pdf['GBDT'] = rf_predict,ada_predict,gbdt_predict\n",
    "    pdf['predict'] = pdf['RF'] + pdf['ADA'] + pdf['GBDT']\n",
    "    pdf = pdf.sort_values(by='predict',ascending=False)\n",
    "    sort_sec = [x[0] for x in pdf.index.tolist()]\n",
    "    \n",
    "    fdf_dic[day] = fdf\n",
    "    sec_dic[day] = sort_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(fdf_dic,open(file+'fea_imp','wb'))\n",
    "pickle.dump(sec_dic,open(file+'sec','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###sec：\n",
    "###key：时间截面\n",
    "###时间截面对应的股票收益率列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fea_imp = pickle.load(open(file+'fea_imp','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fea_imp\n",
    "imp_file = file+'imp/'\n",
    "sum_fea = pd.DataFrame()\n",
    "for k in fea_imp.keys():\n",
    "    fea_imp[k].to_excel(imp_file+k+'.xls')\n",
    "    sum_fea = pd.concat([sum_fea,fea_imp[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssf = pd.DataFrame(sum_fea['importances'].groupby(sum_fea['feature']).sum())\n",
    "ssf = ssf.sort_values(by='importances',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用到的特征的总数： 115\n"
     ]
    }
   ],
   "source": [
    "print('使用到的特征的总数：',ssf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssf.to_excel(file+'特征重要度汇总.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pbMRQ</th>\n",
       "      <td>18.355171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_ocf_to_sales</th>\n",
       "      <td>11.048004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psTTM</th>\n",
       "      <td>9.978842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inv_turn</th>\n",
       "      <td>8.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcfNcfTTM</th>\n",
       "      <td>7.255700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar_turn</th>\n",
       "      <td>6.901118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peTTM</th>\n",
       "      <td>6.184212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skew20</th>\n",
       "      <td>4.667628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev20</th>\n",
       "      <td>2.793402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocf_yoy</th>\n",
       "      <td>2.219009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurt20</th>\n",
       "      <td>2.120178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invturn_days</th>\n",
       "      <td>1.841091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom60</th>\n",
       "      <td>1.782486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equity_yoy</th>\n",
       "      <td>1.708694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profit_to_gr</th>\n",
       "      <td>1.688443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_fa_trun</th>\n",
       "      <td>1.619519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_adminexp_to_gr</th>\n",
       "      <td>1.485016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invest_capital</th>\n",
       "      <td>1.318102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_saleexp_to_gr</th>\n",
       "      <td>1.305817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finaexp_of_gr</th>\n",
       "      <td>1.155056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importances\n",
       "feature                      \n",
       "pbMRQ               18.355171\n",
       "q_ocf_to_sales      11.048004\n",
       "psTTM                9.978842\n",
       "inv_turn             8.008618\n",
       "pcfNcfTTM            7.255700\n",
       "ar_turn              6.901118\n",
       "peTTM                6.184212\n",
       "skew20               4.667628\n",
       "rev20                2.793402\n",
       "ocf_yoy              2.219009\n",
       "kurt20               2.120178\n",
       "invturn_days         1.841091\n",
       "mom60                1.782486\n",
       "equity_yoy           1.708694\n",
       "profit_to_gr         1.688443\n",
       "total_fa_trun        1.619519\n",
       "q_adminexp_to_gr     1.485016\n",
       "invest_capital       1.318102\n",
       "q_saleexp_to_gr      1.305817\n",
       "finaexp_of_gr        1.155056"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssf[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
